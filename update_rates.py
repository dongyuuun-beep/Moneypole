import requests # ì›¹í˜ì´ì§€ í†µì‹  ë° API í˜¸ì¶œì„ ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ì…ë‹ˆë‹¤.
import json # JSON ë°ì´í„°ë¥¼ ë‹¤ë£¨ê¸° ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ì…ë‹ˆë‹¤.
import os # ì‹œìŠ¤í…œ í™˜ê²½ë³€ìˆ˜(API í‚¤ ë“±)ë¥¼ ë¶ˆëŸ¬ì˜¤ê¸° ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ì…ë‹ˆë‹¤.
from datetime import datetime # ê¸ˆë¦¬ ë³€ë™ ì´ë ¥ì— ë‚ ì§œë¥¼ ê¸°ë¡í•˜ê¸° ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ì…ë‹ˆë‹¤.
from bs4 import BeautifulSoup # ì›¹í˜ì´ì§€ í¬ë¡¤ë§(HTML ë¶„ì„)ì„ ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ì…ë‹ˆë‹¤.

# 1. í™˜ê²½ ì„¤ì • ë° ê¸°ë³¸ ë³€ìˆ˜ ì •ì˜
API_KEY = os.environ.get('FSS_API_KEY') # GitHub Secretsì—ì„œ API í‚¤ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.
DATA_FILE = 'data.json' # ë°ì´í„°ê°€ ëˆ„ì ë˜ì–´ ì €ì¥ë  íŒŒì¼ëª…ì…ë‹ˆë‹¤.
FIN_GROUPS = ["020000", "030300"] # 020000: ì‹œì¤‘ì€í–‰, 030300: ì €ì¶•ì€í–‰ ì½”ë“œì…ë‹ˆë‹¤.

# 2. ê¸°ì¡´ ë°ì´í„° ë¡œë“œ í•¨ìˆ˜ (íˆìŠ¤í† ë¦¬ ìœ ì§€ë¥¼ ìœ„í•´ í•„ìˆ˜)
def load_existing_data():
    if os.path.exists(DATA_FILE): # ë°ì´í„° íŒŒì¼ì´ ì´ë¯¸ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸í•©ë‹ˆë‹¤.
        with open(DATA_FILE, 'r', encoding='utf-8') as f: # í•œê¸€ ê¹¨ì§ ë°©ì§€ë¥¼ ìœ„í•´ UTF-8ë¡œ ì—½ë‹ˆë‹¤.
            return json.load(f) # ê¸°ì¡´ íŒŒì¼ì˜ ë°ì´í„°ë¥¼ íŒŒì´ì¬ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜í•˜ì—¬ ë°˜í™˜í•©ë‹ˆë‹¤.
    return [] # íŒŒì¼ì´ ì—†ìœ¼ë©´ ë¹ˆ ë¦¬ìŠ¤íŠ¸ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.

# 3. [API] ì˜ˆê¸ˆ/ì ê¸ˆ ì „ì²´ í˜ì´ì§€ ìˆ˜ì§‘ í•¨ìˆ˜
def fetch_all_products(p_type):
    # ì˜ˆê¸ˆ(deposit)ê³¼ ì ê¸ˆ(savings)ì— ë§ì¶° API ì—”ë“œí¬ì¸íŠ¸ë¥¼ ì„¤ì •í•©ë‹ˆë‹¤.
    endpoint = "depositProductsSearch.json" if p_type == "deposit" else "savingProductsSearch.json"
    all_products = [] # ì „ì²´ ìƒí’ˆì„ ë‹´ì„ ë¦¬ìŠ¤íŠ¸ì…ë‹ˆë‹¤.
    
    for group in FIN_GROUPS: # ì‹œì¤‘ì€í–‰ê³¼ ì €ì¶•ì€í–‰ì„ ë²ˆê°ˆì•„ ì¡°íšŒí•©ë‹ˆë‹¤.
        page_no = 1 # í•­ìƒ 1í˜ì´ì§€ë¶€í„° ì‹œì‘í•©ë‹ˆë‹¤.
        while True: # ë‹¤ìŒ í˜ì´ì§€ê°€ ì—†ì„ ë•Œê¹Œì§€ ê³„ì† ë°˜ë³µí•©ë‹ˆë‹¤.
            url = f"http://finlife.fss.or.kr/finlifeapi/{endpoint}?auth={API_KEY}&topFinGrpNo={group}&pageNo={page_no}"
            res = requests.get(url) # API ì„œë²„ì— ìš”ì²­ì„ ë³´ëƒ…ë‹ˆë‹¤.
            if res.status_code != 200: break # ì—ëŸ¬ ë°œìƒ ì‹œ ë°˜ë³µì„ ì¤‘ë‹¨í•©ë‹ˆë‹¤.
            
            data = res.json().get('result', {}) # ì‘ë‹µì—ì„œ 'result' ë°ì´í„°ë§Œ ì¶”ì¶œí•©ë‹ˆë‹¤.
            base_list = data.get('baseList', []) # ê¸°ë³¸ ì •ë³´(ì€í–‰ëª…, ìƒí’ˆëª… ë“±) ë¦¬ìŠ¤íŠ¸ì…ë‹ˆë‹¤.
            opt_list = data.get('optionList', []) # ê¸ˆë¦¬ ì •ë³´ ë¦¬ìŠ¤íŠ¸ì…ë‹ˆë‹¤.
            
            # ê¸ˆë¦¬ ì •ë³´ ë§µí•‘ (12ê°œì›” ê¸°ì¤€)
            rate_map = {}
            for opt in opt_list:
                code = opt['fin_prdt_cd'] # ìƒí’ˆ ì½”ë“œë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.
                if str(opt['save_trm']) == "12": # 12ê°œì›” ê°€ì… ê¸°ì¤€ ë°ì´í„°ë§Œ ê°€ì ¸ì˜µë‹ˆë‹¤.
                    rate_map[code] = {
                        "max": float(opt['intr_rate2'] or 0), # ìµœê³  ìš°ëŒ€ ê¸ˆë¦¬
                        "base": float(opt['intr_rate'] or 0), # ê¸°ë³¸ ê¸ˆë¦¬
                        "intr_type": opt['intr_rate_type'] # ë‹¨ë¦¬/ë³µë¦¬ ì—¬ë¶€
                    }
            
            # ê¸°ë³¸ ì •ë³´ì™€ ê¸ˆë¦¬ ì •ë³´ë¥¼ ê²°í•©í•©ë‹ˆë‹¤.
            for base in base_list:
                code = base['fin_prdt_cd']
                if code in rate_map: # ê¸ˆë¦¬ ì •ë³´ê°€ ìˆëŠ” ìƒí’ˆë§Œ ì¶”ê°€í•©ë‹ˆë‹¤.
                    all_products.append({
                        "id": code, # ê³ ìœ  ì‹ë³„ìì…ë‹ˆë‹¤.
                        "bank": base['kor_co_nm'], # ì€í–‰ëª…
                        "name": base['fin_prdt_nm'], # ìƒí’ˆëª…
                        "spcl_cnd": base.get('spcl_cnd', ''), # ìš°ëŒ€ ê¸ˆë¦¬ ì¡°ê±´
                        "max": rate_map[code]['max'],
                        "base": rate_map[code]['base'],
                        "intr_type": rate_map[code]['intr_type'],
                        "type": p_type # deposit ë˜ëŠ” savings
                    })
            
            max_page = data.get('max_page_no', 1) # ì „ì²´ í˜ì´ì§€ ìˆ˜ë¥¼ í™•ì¸í•©ë‹ˆë‹¤.
            if page_no >= max_page: break # ë§ˆì§€ë§‰ í˜ì´ì§€ë©´ ë°˜ë³µë¬¸ì„ íƒˆì¶œí•©ë‹ˆë‹¤.
            page_no += 1 # ë‹¤ìŒ í˜ì´ì§€ ì¡°íšŒë¥¼ ìœ„í•´ í˜ì´ì§€ ë²ˆí˜¸ë¥¼ ì˜¬ë¦½ë‹ˆë‹¤.
            
    return all_products # ìˆ˜ì§‘ëœ ì „ì²´ API ìƒí’ˆ ë¦¬ìŠ¤íŠ¸ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
# 4. [í¬ë¡¤ë§] íŒŒí‚¹í†µì¥(ì…ì¶œê¸ˆììœ ì˜ˆê¸ˆ) ë°ì´í„° ìˆ˜ì§‘ í•¨ìˆ˜
def crawl_parking_accounts():
    parking_products = [] # íŒŒí‚¹í†µì¥ ë°ì´í„°ë¥¼ ë‹´ì„ ë¦¬ìŠ¤íŠ¸ì…ë‹ˆë‹¤.
    # ê¸ˆìœµê°ë…ì› 'ì…ì¶œê¸ˆììœ ì˜ˆê¸ˆ' ëª©ë¡ í˜ì´ì§€ URLì…ë‹ˆë‹¤.
    url = "https://finlife.fss.or.kr/finlife/svings/fdrmDpst/list.do?menuNo=700002"
    
    try:
        # í¬ë¡¤ë§ ë´‡ ì°¨ë‹¨ì„ í”¼í•˜ê¸° ìœ„í•´ User-Agent í—¤ë”ë¥¼ ì„¤ì •í•©ë‹ˆë‹¤.
        headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'}
        res = requests.get(url, headers=headers)
        res.raise_for_status()
        
        # BeautifulSoupìœ¼ë¡œ HTMLì„ ë¶„ì„í•©ë‹ˆë‹¤.
        soup = BeautifulSoup(res.text, 'html.parser')
        
        # ê¸ˆê°ì› í˜ì´ì§€ì˜ ì‹¤ì œ í…Œì´ë¸” í–‰(tr)ì„ ì„ íƒí•©ë‹ˆë‹¤. (ë³´í†µ #resultList ë‚´ì˜ tr)
        # í…Œì´ë¸” êµ¬ì¡°ì— ë”°ë¼ 'table tbody tr' ë˜ëŠ” êµ¬ì²´ì ì¸ IDë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.
        items = soup.select('#resultList tr') 
        
        if not items: # ë§Œì•½ IDë¡œ ëª» ì°¾ì„ ê²½ìš° ì¼ë°˜ì ì¸ í…Œì´ë¸” êµ¬ì¡°ë¡œ ì‹œë„í•©ë‹ˆë‹¤.
            items = soup.select('table.as_table tbody tr')

        for index, item in enumerate(items):
            tds = item.select('td')
            if len(tds) < 4: continue # í•„ìš”í•œ ì—´ì´ ë¶€ì¡±í•˜ë©´ ê±´ë„ˆëœë‹ˆë‹¤.

            # 1. strip()ì„ ì‚¬ìš©í•˜ì—¬ \r\n\t ë“± ë¶ˆí•„ìš”í•œ ê³µë°±ì„ ì™„ì „íˆ ì œê±°í•©ë‹ˆë‹¤.
            bank_name = tds[1].text.strip() # ê¸ˆìœµíšŒì‚¬ëª…
            prod_name = tds[2].text.strip() # ìƒí’ˆëª…
            
            # 2. ì •ê·œì‹ì„ ì‚¬ìš©í•˜ì—¬ í…ìŠ¤íŠ¸ ë‚´ì—ì„œ ìˆ«ì(ê¸ˆë¦¬)ë§Œ ì¶”ì¶œí•©ë‹ˆë‹¤.
            import re
            rate_text = tds[3].text.strip() # ì„¸ì „ ê¸ˆë¦¬ ì¹¸
            rate_match = re.search(r"(\d+\.?\d*)", rate_text)
            rate_val = float(rate_match.group(1)) if rate_match else 0.0

            # ê¸ˆë¦¬ê°€ ì •ìƒì ìœ¼ë¡œ ì¶”ì¶œëœ ê²½ìš°ì—ë§Œ ì¶”ê°€í•©ë‹ˆë‹¤.
            if rate_val > 0:
                parking_products.append({
                    "id": f"parking_{index}",
                    "bank": bank_name,
                    "name": prod_name,
                    "spcl_cnd": "ì…ì¶œê¸ˆì´ ììœ ë¡œìš´ íŒŒí‚¹í†µì¥ì…ë‹ˆë‹¤.",
                    "max": rate_val,
                    "base": rate_val,
                    "intr_type": "S",
                    "type": "parking"
                })
                
        print(f"ğŸ” íŒŒí‚¹í†µì¥ í¬ë¡¤ë§ ê²°ê³¼: {len(parking_products)}ê±´ ìˆ˜ì§‘ë¨")

    except Exception as e:
        print(f"âš ï¸ íŒŒí‚¹í†µì¥ í¬ë¡¤ë§ ì¤‘ ì—ëŸ¬ ë°œìƒ: {e}")
        
    return parking_products

# 5. ë©”ì¸ ì‹¤í–‰ ë¡œì§ (API + í¬ë¡¤ë§ ë³‘í•© ë° íˆìŠ¤í† ë¦¬ ì—…ë°ì´íŠ¸)
def main():
    master_data = load_existing_data() # ê¸°ì¡´ì— ì €ì¥ëœ ë°ì´í„°(íˆìŠ¤í† ë¦¬ í¬í•¨)ë¥¼ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤.
    today = datetime.now().strftime('%Y-%m-%d') # '202X-XX-XX' í˜•íƒœì˜ ì˜¤ëŠ˜ ë‚ ì§œ ë¬¸ìì—´ì„ ë§Œë“­ë‹ˆë‹¤.
    
    # í¬ë¡¤ë§ê³¼ APIê°€ ì•„ë‹Œ ìˆœìˆ˜ 'ìˆ˜ë™ ê´€ë¦¬' í’ˆëª©ë§Œ ë”°ë¡œ ë³´ì¡´í•©ë‹ˆë‹¤ (CMA, ë°œí–‰ì–´ìŒ ë“±).
    manual_types = ['cma', 'bill', 'els', 'bond']
    preserved_data = [item for item in master_data if item.get('type') in manual_types]
    
    print("ğŸš€ API(ì˜ˆ/ì ê¸ˆ) ë° í¬ë¡¤ë§(íŒŒí‚¹í†µì¥) ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘...")
    api_deposits = fetch_all_products("deposit") # APIë¡œ ì˜ˆê¸ˆì„ ê°€ì ¸ì˜µë‹ˆë‹¤.
    ##api_savings = fetch_all_products("savings") # APIë¡œ ì ê¸ˆì„ ê°€ì ¸ì˜µë‹ˆë‹¤.
    crawled_parking = crawl_parking_accounts() # í¬ë¡¤ë§ìœ¼ë¡œ íŒŒí‚¹í†µì¥ì„ ê°€ì ¸ì˜µë‹ˆë‹¤.
    
    # ìˆ˜ì§‘í•œ 3ê°€ì§€ ì¢…ë¥˜ì˜ ë°ì´í„°ë¥¼ í•˜ë‚˜ì˜ í° ë¦¬ìŠ¤íŠ¸ë¡œ í•©ì¹©ë‹ˆë‹¤.
    all_new_data =  crawled_parking #+ api_deposits + api_savings
    updated_items = [] # ìµœì¢… ì—…ë°ì´íŠ¸ ë  ì•„ì´í…œë“¤ì„ ë‹´ì„ ë¦¬ìŠ¤íŠ¸ì…ë‹ˆë‹¤.
    
    # ê¸ˆë¦¬ ë³€ë™ ì¶”ì´(Graph) ë¡œì§ì„ ì ìš©í•©ë‹ˆë‹¤.
    for new_item in all_new_data:
        # ê¸°ì¡´ ë°ì´í„° ì¤‘ì—ì„œ ì§€ê¸ˆ ì²˜ë¦¬ ì¤‘ì¸ ìƒí’ˆê³¼ ë™ì¼í•œ IDë¥¼ ê°€ì§„ ê²ƒì„ ì°¾ìŠµë‹ˆë‹¤.
        existing = next((item for item in master_data if item.get('id') == new_item['id']), None)
        
        history = [] # íˆìŠ¤í† ë¦¬ë¥¼ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸ì…ë‹ˆë‹¤.
        if existing and 'history' in existing:
            history = existing['history'] # ê¸°ì¡´ íˆìŠ¤í† ë¦¬ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.
            # ìµœê·¼ ê¸°ë¡ëœ ê¸ˆë¦¬ì™€ ì˜¤ëŠ˜ í™•ì¸í•œ ê¸ˆë¦¬ê°€ ë‹¤ë¥¼ ë•Œë§Œ ìƒˆë¡œìš´ ê¸°ë¡ì„ ë‚¨ê¹ë‹ˆë‹¤.
            if history and history[-1]['rate'] != new_item['max']:
                history.append({"date": today, "rate": new_item['max']})
        else:
            # ì™„ì „íˆ ì²˜ìŒ ìˆ˜ì§‘ë˜ëŠ” ìƒí’ˆì´ë©´ ì˜¤ëŠ˜ ë‚ ì§œë¡œ ì²« ê¸°ë¡ì„ ìƒì„±í•©ë‹ˆë‹¤.
            history = [{"date": today, "rate": new_item['max']}]
            
        new_item['history'] = history # ê°±ì‹ ëœ íˆìŠ¤í† ë¦¬ë¥¼ ìƒí’ˆ ë°ì´í„°ì— ë„£ìŠµë‹ˆë‹¤.
        updated_items.append(new_item) # ì—…ë°ì´íŠ¸ëœ ìƒí’ˆì„ ìµœì¢… ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€í•©ë‹ˆë‹¤.
        
    # ìˆ˜ë™ ë³´ì¡´ ë°ì´í„°ì™€ ìƒˆë¡œ ìˆ˜ì§‘/ê°±ì‹ ëœ ë°ì´í„°ë¥¼ í•©ì¹©ë‹ˆë‹¤.
    final_output = preserved_data + updated_items
    
    # ìµœì¢… ê²°ê³¼ë¬¼ì„ data.json íŒŒì¼ì— ì €ì¥(ë®ì–´ì“°ê¸°)í•©ë‹ˆë‹¤.
    with open(DATA_FILE, 'w', encoding='utf-8') as f:
        json.dump(final_output, f, ensure_ascii=False, indent=2) # ê°€ë…ì„±ì„ ìœ„í•´ ë“¤ì—¬ì“°ê¸° 2ì¹¸ì„ ì ìš©í•©ë‹ˆë‹¤.
        
    print(f"âœ… ì—…ë°ì´íŠ¸ ì™„ë£Œ! (ìˆ˜ë™ ë³´ì¡´: {len(preserved_data)}ê±´, API+í¬ë¡¤ë§ ê°±ì‹ : {len(updated_items)}ê±´)")

if __name__ == "__main__":
    main() # íŒŒì´ì¬ íŒŒì¼ ì‹¤í–‰ ì‹œ main() í•¨ìˆ˜ë¥¼ êµ¬ë™í•©ë‹ˆë‹¤.
